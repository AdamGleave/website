---
abstract: 'Deep reinforcement learning (RL) policies are known to be vulnerable to
  adversarial perturbations to their observations, similar to adversarial examples
  for classifiers. However, an attacker is not usually able to directly modify another
  agent''s observations. This might lead one to wonder: is it possible to attack an
  RL agent simply by choosing an adversarial policy acting in a multi-agent environment
  so as to create natural observations that are adversarial? We demonstrate the existence
  of adversarial policies in zero-sum games between simulated humanoid robots with
  proprioceptive observations, against state-of-the-art victims trained via self-play
  to be robust to opponents. The adversarial policies reliably win against the victims
  but generate seemingly random and uncoordinated behavior. We find that these policies
  are more successful in high-dimensional environments, and induce substantially different
  activations in the victim policy network than when the victim plays against a normal
  opponent. Videos are available at https://adversarialpolicies.github.io/.'
abstract_short: ' '
authors: [AdamGleave, MichaelDennis, CodyWild, NeelKant, SergeyLevine, StuartRussell]
date: '2020-02-10'
highlight: false
image_preview: ''
math: false
publication: International Conference on Learning Representations (ICLR)
publication_short: ICLR
publication_types: ['1']
selected: false
title: 'Adversarial Policies: Attacking Deep Reinforcement Learning'
url_code: https://github.com/HumanCompatibleAI/adversarial-policies
url_pdf: https://arxiv.org/pdf/1905.10615.pdf
links:
  - name: OpenReview
    url: https://openreview.net/forum?id=HJgEMpVFwB
  - name: Poster
    url: https://docs.google.com/presentation/d/1mGhe9M2LFaT0PF2VEvIxLp_TOSHX_qSULcauHxZj5Hc/edit
  - name: Blog
    url: https://bair.berkeley.edu/blog/2020/03/27/attacks/
url_dataset: ''
url_project: https://adversarialpolicies.github.io
url_slides: https://docs.google.com/presentation/d/1FgnomI1_iKMrOFZA3DGSKtvdJS-aCBhSN6rgz7TKERs/edit?usp=sharing
url_video: https://slideslive.com/38922702/contributed-talk-adversarial-policies-attacking-deep-reinforcement-learning
---

