---
abstract: Inverse Reinforcement Learning (IRL) algorithms infer a reward function that explains demonstrations provided by an expert acting in the environment. Maximum Causal Entropy (MCE) IRL is currently the most popular formulation of IRL, with numerous extensions. In this tutorial, we present a compressed derivation of MCE IRL and the key results from contemporary implementations of MCE IRL algorithms. We hope this will serve both as an introductory resource for those new to the field, and as a concise reference for those already familiar with these topics.
abstract_short: ' '
authors: [AdamGleave, SamToyer]
date: '2022-03-22'
highlight: false
image_preview: ''
math: false
publication: arXiv 
publication_types: ['3']
selected: false
title: A Primer on Maximum Causal Entropy Inverse Reinforcement Learning 
url_pdf: https://arxiv.org/pdf/2203.11409.pdf 
url_dataset: ''
url_project: ''
url_slides: '' 
url_video: ''
---

